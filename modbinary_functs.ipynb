{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modbinary_functs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOe+uz2y98xKIv+WRMUzjK1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gevenbly/TensorAlgs/blob/main/modbinary_functs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCml5n60w2Dq"
      },
      "source": [
        "def define_ham(blocksize):\n",
        "  \"\"\" \n",
        "  Define Hamiltonian (quantum critical Ising), perform preliminary blocking \n",
        "  of several sites into an effective site.\n",
        "  \"\"\"\n",
        "\n",
        "  # define Pauli matrices\n",
        "  sX = np.array([[0, 1], [1, 0]], dtype=float)\n",
        "  sZ = np.array([[1, 0], [0, -1]], dtype=float)\n",
        "\n",
        "  # define Ising local Hamiltonian\n",
        "  ham_orig = (tprod(sX, sX) - 0.5*tprod(sZ, np.eye(2)) - \n",
        "              0.5*tprod(np.eye(2), sZ))\n",
        "\n",
        "  # shift Hamiltonian to ensure negative defined\n",
        "  en_shift = max(LA.eigh(ham_orig)[0])\n",
        "  ham_loc = ham_orig - en_shift*np.eye(4)\n",
        "\n",
        "  # define block Hamiltonians \n",
        "  d0 = 2 # initial local dim\n",
        "  d1 = d0**blocksize # local dim after blocking\n",
        "\n",
        "  if blocksize==2:\n",
        "    ham_block = (0.5*tprod(ham_loc, np.eye(d0**2)) + \n",
        "                 1.0*tprod(np.eye(d0**1), ham_loc, np.eye(d0**1)) +\n",
        "                 0.5*tprod(np.eye(d0**2), ham_loc)\n",
        "                 ).reshape(d0*np.ones(8, dtype=int))\n",
        "    hamAB_init = ham_block.transpose(0,1,4,3,5,6,8,7\n",
        "                                    ).reshape(d1, d1, d1, d1)\n",
        "    hamBA_init = ham_block.transpose(1,0,3,4,6,5,7,8\n",
        "                                    ).reshape(d1, d1, d1, d1)\n",
        "  elif blocksize==3:\n",
        "    ham_block = (1.0*tprod(np.eye(d0**1), ham_loc, np.eye(d0**3)) + \n",
        "                 1.0*tprod(np.eye(d0**2), ham_loc, np.eye(d0**2)) +\n",
        "                 1.0*tprod(np.eye(d0**3), ham_loc, np.eye(d0**1))\n",
        "                 ).reshape(d0*np.ones(12, dtype=int))\n",
        "    hamAB_init = ham_block.transpose(0,1,2,5,4,3,6,7,8,11,10,9\n",
        "                                    ).reshape(d1, d1, d1, d1)\n",
        "    hamBA_init = ham_block.transpose(2,1,0,3,4,5,8,7,6,9,10,11\n",
        "                                    ).reshape(d1, d1, d1, d1)\n",
        "  elif blocksize==4:\n",
        "    ham_block = (0.5*tprod(np.eye(d0**1), ham_loc, np.eye(d0**5)) + \n",
        "                1.0*tprod(np.eye(d0**2), ham_loc, np.eye(d0**4)) + \n",
        "                1.0*tprod(np.eye(d0**3), ham_loc, np.eye(d0**3)) +\n",
        "                1.0*tprod(np.eye(d0**4), ham_loc, np.eye(d0**2)) +\n",
        "                0.5*tprod(np.eye(d0**5), ham_loc, np.eye(d0**1))\n",
        "                ).reshape(d0*np.ones(16, dtype=int))\n",
        "    hamAB_init = ham_block.transpose(0,1,2,3,7,6,5,4,8,9,10,11,15,14,13,12\n",
        "                                    ).reshape(d1, d1, d1, d1)\n",
        "    hamBA_init = ham_block.transpose(3,2,1,0,4,5,6,7,11,10,9,8,12,13,14,15\n",
        "                                    ).reshape(d1, d1, d1, d1)\n",
        "  \n",
        "  return hamAB_init, hamBA_init, en_shift"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N8zMmAKQYIJ"
      },
      "source": [
        "def initialize(chi, chimid, hamAB_init, hamBA_init, layers):\n",
        "  \"\"\" Initialize the MERA tensors \"\"\"\n",
        "\n",
        "  # Initialize the MERA tensors\n",
        "  d1 = hamAB_init.shape[0]\n",
        "  iso_temp = orthogonalize(np.random.rand(d1, min(chimid, d1)))\n",
        "  uC = [tprod(iso_temp, iso_temp, do_matricize=False)]\n",
        "  wC = [orthogonalize(np.random.rand(d1, uC[0].shape[2], chi), partition=2)]\n",
        "  vC = [orthogonalize(np.random.rand(d1, uC[0].shape[2], chi), partition=2)]\n",
        "  for k in range(layers-1):\n",
        "    iso_temp = orthogonalize(np.random.rand(chi, chimid))\n",
        "    uC.append(tprod(iso_temp, iso_temp, do_matricize=False))\n",
        "    wC.append(orthogonalize(np.random.rand(chi, chimid, chi), partition=2))\n",
        "    vC.append(orthogonalize(np.random.rand(chi, chimid, chi), partition=2))\n",
        "  \n",
        "  # initialize density matrices and effective Hamiltonians\n",
        "  rhoAB = [0]\n",
        "  rhoBA = [0]\n",
        "  hamAB = [hamAB_init]\n",
        "  hamBA = [hamBA_init]\n",
        "  for k in range(layers):\n",
        "    rhoAB.append(np.eye(chi**2).reshape(chi, chi, chi, chi))\n",
        "    rhoBA.append(np.eye(chi**2).reshape(chi, chi, chi, chi))\n",
        "    hamAB.append(np.zeros((chi, chi, chi, chi)))\n",
        "    hamBA.append(np.zeros((chi, chi, chi, chi)))\n",
        "  \n",
        "  return hamAB, hamBA, wC, vC, uC, rhoAB, rhoBA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSLzMfwC6Jxy"
      },
      "source": [
        "def define_networks(hamAB, hamBA, wC, vC, uC, rhoAB, rhoBA):\n",
        "  \"\"\" Define and plot all principle networks \"\"\"\n",
        "\n",
        "  # Define the `M` principle network\n",
        "  connects_M = [[3,5,9], [1,5,7], [1,2,3,4], [4,6,10], [2,6,8], [7,8,9,10]]\n",
        "  tensors_M = [vC, vC, hamBA, wC, wC, rhoAB]\n",
        "  order_M = ncon_solver(tensors_M, connects_M)[0]\n",
        "  dims_M = [tensor.shape for tensor in tensors_M]\n",
        "  names_M = ['v', 'v', 'hBA', 'w', 'w', 'rhoAB']\n",
        "  coords_M = [(-0.5,1),(-0.5,-1), (-0.3,-0.2,0.3,0.2),(0.5,1),(0.5,-1),(0.2)]\n",
        "  colors_M = [0,0,1,2,2,3]\n",
        "\n",
        "  # Define the `L` principle network\n",
        "  connects_L = [[3,6,13], [1,8,11], [4,5,6,7], [2,5,8,9], [1,2,3,4], \n",
        "                [10,7,14], [10,9,12], [11,12,13,14]]\n",
        "  tensors_L = [wC, wC, uC, uC, hamAB, vC, vC, rhoBA]\n",
        "  order_L = ncon_solver(tensors_L, connects_L)[0]\n",
        "  dims_L = [tensor.shape for tensor in tensors_L]\n",
        "  names_L = ['w', 'w', 'u', 'u', 'hAB', 'v', 'v', 'rhoBA']\n",
        "  coords_L = [(-0.5, 1.5), (-0.5, -1.5), (-0.3,0.5,0.3,0.9), (-0.3,-0.5,0.3,-0.9), \n",
        "              (-0.6,-0.2,-0.1,0.2), (0.5, 1.5), (0.5, -1.5), (0.2)]\n",
        "  colors_L = [2,2,4,4,1,0,0,3]\n",
        "\n",
        "  # Define the `C` principle network\n",
        "  connects_C = [[5,6,13], [5,9,11], [3,4,6,8], [1,2,9,10], [1,2,3,4], [7,8,14],\n",
        "                [7,10,12], [11,12,13,14]]\n",
        "  tensors_C = [wC, wC, uC, uC, hamBA, vC, vC, rhoBA]\n",
        "  order_C = ncon_solver(tensors_C, connects_C)[0]\n",
        "  dims_C = [tensor.shape for tensor in tensors_C]\n",
        "  names_C = ['w', 'w', 'u', 'u', 'hBA', 'v', 'v', 'rhoBA']\n",
        "  coords_C = [(-0.5, 1.5), (-0.5, -1.5), (-0.3,0.5,0.3,0.9), (-0.3,-0.5,0.3,-0.9), \n",
        "              (-0.3,-0.2,0.3,0.2), (0.5, 1.5), (0.5, -1.5), (0.2)]\n",
        "  colors_C = [2,2,4,4,1,0,0,3]\n",
        "\n",
        "  # Define the `R` principle network\n",
        "  connects_R = [[10,6,13], [10,8,11], [5,3,6,7], [5,1,8,9], [1,2,3,4], [4,7,14],\n",
        "                [2,9,12], [11,12,13,14]]\n",
        "  tensors_R = [wC, wC, uC, uC, hamAB, vC, vC, rhoBA]\n",
        "  order_R = ncon_solver(tensors_R, connects_R)[0]\n",
        "  dims_R = [tensor.shape for tensor in tensors_R]\n",
        "  names_R = ['w', 'w', 'u', 'u', 'hAB', 'v', 'v', 'rhoBA']\n",
        "  coords_R = [(-0.5, 1.5), (-0.5, -1.5), (-0.3,0.5,0.3,0.9), (-0.3,-0.5,0.3,-0.9), \n",
        "              (0.6,-0.2,0.1,0.2), (0.5, 1.5), (0.5, -1.5), (0.2)]\n",
        "  colors_R = [2,2,4,4,1,0,0,3]\n",
        "\n",
        "  # Plot all principle networks\n",
        "  fig = plt.figure(figsize=(24,24))\n",
        "  figM = draw_network(connects_M, order=order_M, dims=dims_M, coords=coords_M, \n",
        "                      names=names_M, colors=colors_M, title='M-diagrams', \n",
        "                      draw_labels=False, show_costs=True, legend_extend=2.5, \n",
        "                      fig=fig, subplot=141, env_pad=(-0.4,-0.4))\n",
        "  figL = draw_network(connects_L, order=order_L, dims=dims_L, coords=coords_L, \n",
        "                      names=names_L, colors=colors_L, title='L-diagrams', \n",
        "                      draw_labels=False, show_costs=True, legend_extend=2.5, \n",
        "                      fig=fig, subplot=142, env_pad=(-0.4,-0.4))\n",
        "  figC = draw_network(connects_C, order=order_C, dims=dims_C, coords=coords_C, \n",
        "                      names=names_C, colors=colors_C, title='C-diagrams', \n",
        "                      draw_labels=False, show_costs=True, legend_extend=2.5, \n",
        "                      fig=fig, subplot=143, env_pad=(-0.4,-0.4))\n",
        "  figR = draw_network(connects_R, order=order_R, dims=dims_R, coords=coords_R, \n",
        "                      names=names_R, colors=colors_R, title='R-diagrams', \n",
        "                      draw_labels=False, show_costs=True, legend_extend=2.5, \n",
        "                      fig=fig, subplot=144, env_pad=(-0.4,-0.4))\n",
        "\n",
        "  # Store `connects` and `order` in a dict for later use\n",
        "  network_dict = {'connects_M': connects_M, 'order_M': order_M,\n",
        "                  'connects_L': connects_L, 'order_L': order_L,\n",
        "                  'connects_C': connects_C, 'order_C': order_C,\n",
        "                  'connects_R': connects_R, 'order_R': order_R,}\n",
        "\n",
        "  return network_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec3x6ITl7qrv"
      },
      "source": [
        "def lift_hamiltonian(hamAB, hamBA, w, v, u, rhoAB, rhoBA, network_dict, \n",
        "                     ref_sym=False):\n",
        "  \"\"\" Lift the Hamiltonian through one MERA layer \"\"\"\n",
        "\n",
        "  hamAB_lift = xcon([v, v, hamBA, w, w, rhoAB], \n",
        "                    network_dict['connects_M'], \n",
        "                    order=network_dict['order_M'], which_envs=5)\n",
        "\n",
        "  hamBA_temp0 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                     network_dict['connects_L'], \n",
        "                     order=network_dict['order_L'], which_envs=7)\n",
        "\n",
        "  hamBA_temp1 = xcon([w, w, u, u, hamBA, v, v, rhoBA], \n",
        "                     network_dict['connects_C'], \n",
        "                     order=network_dict['order_C'], which_envs=7)\n",
        "\n",
        "  if ref_sym is True:\n",
        "    hamBA_temp2 = hamBA_temp0.transpose(1,0,3,2)\n",
        "  else:\n",
        "    hamBA_temp2 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                      network_dict['connects_R'], \n",
        "                      order=network_dict['order_R'], which_envs=7)\n",
        "  \n",
        "  hamBA_lift = hamBA_temp0 + hamBA_temp1 + hamBA_temp2\n",
        "\n",
        "  return hamAB_lift, hamBA_lift"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt89CEM2NS2y"
      },
      "source": [
        "def lower_density(hamAB, hamBA, w, v, u, rhoAB, rhoBA, network_dict, \n",
        "                  ref_sym=False):\n",
        "  \"\"\" Lower the density matrix through one MERA layer \"\"\"\n",
        "\n",
        "  rhoBA_temp0 = xcon([v, v, hamBA, w, w, rhoAB], \n",
        "                     network_dict['connects_M'], \n",
        "                     order=network_dict['order_M'], which_envs=2)\n",
        "\n",
        "  rhoAB_temp0 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                     network_dict['connects_L'], \n",
        "                     order=network_dict['order_L'], which_envs=4)\n",
        "\n",
        "  rhoBA_temp1 = xcon([w, w, u, u, hamBA, v, v, rhoBA], \n",
        "                     network_dict['connects_C'], \n",
        "                     order=network_dict['order_C'], which_envs=4)\n",
        "  \n",
        "  if ref_sym is True:\n",
        "    rhoAB_temp1 = rhoAB_temp0.transpose(1,0,3,2)\n",
        "  else:\n",
        "    rhoAB_temp1 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                      network_dict['connects_R'], \n",
        "                      order=network_dict['order_R'], which_envs=4)\n",
        "  \n",
        "  rhoAB_lower = 0.5*(rhoAB_temp0 + rhoAB_temp1)\n",
        "  rhoBA_lower = 0.5*(rhoBA_temp0 + rhoBA_temp1)\n",
        "\n",
        "  return rhoAB_lower, rhoBA_lower"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48kn9l27ONxp"
      },
      "source": [
        "def optimize_w(hamAB, hamBA, w, v, u, rhoAB, rhoBA, network_dict, \n",
        "               ref_sym=False):\n",
        "  \"\"\" Optimise the `w` isometry \"\"\"\n",
        "\n",
        "  w_env0 = xcon([v, v, hamBA, w, w, rhoAB], network_dict['connects_M'], \n",
        "                order=network_dict['order_M'], which_envs=3)\n",
        "  \n",
        "  if ref_sym is True:\n",
        "    w_env1, w_env3 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                          network_dict['connects_L'], \n",
        "                          order=network_dict['order_L'], \n",
        "                          which_envs=[0,5])\n",
        "  else:\n",
        "    w_env1 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                  network_dict['connects_L'], order=network_dict['order_L'], \n",
        "                  which_envs=0)\n",
        "    \n",
        "    w_env3 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                network_dict['connects_R'], order=network_dict['order_R'], \n",
        "                which_envs=0)\n",
        "  \n",
        "  w_env2 = xcon([w, w, u, u, hamBA, v, v, rhoBA], \n",
        "                network_dict['connects_C'], order=network_dict['order_C'], \n",
        "                which_envs=0)\n",
        "  \n",
        "  w_out = orthogonalize(w_env0 + w_env1 + w_env2 + w_env3, partition=2)\n",
        "\n",
        "  return w_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di3CNfrxZWoQ"
      },
      "source": [
        "def optimize_v(hamAB, hamBA, w, v, u, rhoAB, rhoBA, network_dict, \n",
        "               ref_sym=False):\n",
        "  \"\"\" Optimise the `v` isometry \"\"\"\n",
        "\n",
        "  v_env0 = xcon([v, v, hamBA, w, w, rhoAB], network_dict['connects_M'], \n",
        "                order=network_dict['order_M'], which_envs=0)\n",
        "  \n",
        "  if ref_sym is True:\n",
        "    v_env1, v_env3 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                          network_dict['connects_L'], \n",
        "                          order=network_dict['order_L'], \n",
        "                          which_envs=[0,5])\n",
        "  else:\n",
        "    v_env1 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                  network_dict['connects_L'], order=network_dict['order_L'], \n",
        "                  which_envs=5)\n",
        "    \n",
        "    v_env3 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                  network_dict['connects_R'], order=network_dict['order_R'], \n",
        "                  which_envs=5)\n",
        "  \n",
        "  v_env2 = xcon([w, w, u, u, hamBA, v, v, rhoBA], \n",
        "                network_dict['connects_C'], order=network_dict['order_C'], \n",
        "                which_envs=5)\n",
        "  \n",
        "  v_out = orthogonalize(v_env0 + v_env1 + v_env2 + v_env3, partition=2)\n",
        "\n",
        "  return v_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGciWMuaZXUB"
      },
      "source": [
        "def optimize_u(hamAB, hamBA, w, v, u, rhoAB, rhoBA, network_dict, \n",
        "               ref_sym=False):\n",
        "  \"\"\" Optimise the `u` disentangler \"\"\"\n",
        "  \n",
        "  u_env0 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                network_dict['connects_L'], order=network_dict['order_L'], \n",
        "                which_envs=2)\n",
        "  \n",
        "  u_env1 = xcon([w, w, u, u, hamBA, v, v, rhoBA], \n",
        "                network_dict['connects_C'], order=network_dict['order_C'], \n",
        "                which_envs=2)\n",
        "  \n",
        "  if ref_sym is True:\n",
        "    u_env2 = u_env0.transpose(1,0,3,2)\n",
        "  else:\n",
        "    u_env2 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                  network_dict['connects_R'], order=network_dict['order_R'], \n",
        "                  which_envs=2)\n",
        "  \n",
        "  utot = u_env0 + u_env1 + u_env2\n",
        "  if ref_sym is True:\n",
        "    utot = utot + utot.transpose(1,0,3,2)\n",
        "  \n",
        "  u_out = orthogonalize(utot, partition=2)\n",
        "\n",
        "  return u_out"
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}