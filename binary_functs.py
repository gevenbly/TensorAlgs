# -*- coding: utf-8 -*-
"""binary_functs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ysi8rnluAWSD0I29-b_gj6fT2Yyv1oWb
"""

import numpy as np
from numpy import linalg as LA
import matplotlib.pyplot as plt
from scipy.sparse.linalg import eigsh
from typing import Optional, List, Union, Tuple
from IPython.display import clear_output 
from network_helpers import (
    tprod, orthogonalize, expand_dims, matricize)
from network_contract import solve_order, xcon
from network_render import draw_network

def optimise_MERA(uC, wC, hC, rhoC, network_dict, layers, niter=100, 
                  blocksize=1, en_exact=0):
  """ Algorithm for optimizing a finite MERA via energy minimization"""
  N = 3 * (2**layers) * blocksize
  for k in range(niter):
    # compute the local reduced density matrices
    for z in reversed(range(layers)):
      rhoC[z] = descend_super(uC[z], wC[z], rhoC[z+1], network_dict)

    # begin the variational sweep
    for z in range(layers):
      # update the disentanglers and isometries
      uC[z] = optimize_dis(uC[z],wC[z],hC[z],rhoC[z+1],network_dict)
      wC[z] = optimize_iso(uC[z],wC[z],hC[z],rhoC[z+1],network_dict)
      # compute the coarse-grained Hamiltonian coupling
      hC[z+1] = ascend_super(uC[z], wC[z], hC[z], network_dict)
    
    # update the top tensor
    qtop = optimize_top(hC[layers])
    rhoC[layers] = np.outer(qtop.conj(), qtop).reshape(hC[layers].shape)
    # evaluate the new energy
    energy = np.real(xcon([rhoC[layers], hC[layers]], 
                          [[1,2,3,4,5,6], [1,2,3,4,5,6]])) / (2**layers)
    # print convergence info 
    if np.mod(k, 10) == 1:
      print('Iteration: %d of %d, Energy: %f, Err: %e' %
                (k, niter, energy, energy - en_exact))
      
  return uC, wC, hC, rhoC

def optimize_top(h):
  """ Updates the top tensor of the MERA from the top-level 'h' coupling """

  # form Hamiltonian from periodic translations of the local coupling
  H = (h + h.transpose(1,2,0,4,5,3) + h.transpose(2,0,1,5,3,4))
  # diagonalize Hamiltonian for the ground state
  return eigsh(matricize(H), k=1, which='SA')[1]

def optimize_dis(u,w,h,rho,network_dict):
  """ Updates a disentangler 'u' from its linearized environment """

  # compute the linearized environment of a disentangler
  tensors = [u, u, w, w, w, h, u.conj(), u.conj(), w.conj(), w.conj(), 
             w.conj(), rho]
  u_envsL = xcon(tensors, network_dict['connectsL'], 
                 order=network_dict['orderL'], which_envs=[0,1])
  u_envsR = xcon(tensors, network_dict['connectsR'], 
                 order=network_dict['orderR'], which_envs=[0,1])
  # return the orthogonalized environment
  return -orthogonalize(sum(u_envsL) + sum(u_envsR), partition=2).conj()

def optimize_iso(u,w,h,rho,network_dict):
  """ Updates an isometry 'w' from its linearized environment """

  # compute the linearized environment of an isometry
  tensors = [u, u, w, w, w, h, u.conj(), u.conj(), w.conj(), w.conj(), 
             w.conj(), rho]
  w_envsL = xcon(tensors, network_dict['connectsL'], 
                 order=network_dict['orderL'], which_envs=[2,3,4])
  w_envsR = xcon(tensors, network_dict['connectsR'], 
                 order=network_dict['orderR'], which_envs=[2,3,4])
  # return the orthogonalized environment
  return -orthogonalize(sum(w_envsL) + sum(w_envsR), partition=2).conj()

def descend_super(u,w,rho,network_dict):
  """ implements the (average) descending superoperator of the binary MERA """
  
  tensors = [u, u, w, w, w, [], u.conj(), u.conj(), w.conj(), w.conj(), 
             w.conj(), rho]
  rhominusL = xcon(tensors, network_dict['connectsL'], 
                order=network_dict['orderL'], which_envs=5)
  rhominusR = xcon(tensors, network_dict['connectsR'], 
                order=network_dict['orderR'], which_envs=5)
  return 0.5*(rhominusL + rhominusR)

def ascend_super(u,w,h,network_dict):
  """ implements the sum of ascending superoperators of the binary MERA """

  tensors = [u, u, w, w, w, h, u.conj(), u.conj(), w.conj(), w.conj(), 
             w.conj(), []]
  hplusL = xcon(tensors, network_dict['connectsL'], 
                order=network_dict['orderL'], which_envs=11)
  hplusR = xcon(tensors, network_dict['connectsR'], 
                order=network_dict['orderR'], which_envs=11)
  return hplusL + hplusR

def define_principle(chi, chimid):
  """ defines, solves and plots the principle networks for binary MERA """

  # set network info (needed for making diagrams)
  names = ['u','u','w','w','w','h','u*','u*','w*','w*','w*','rho']
  colors = [0,0,1,1,1,2,0,0,1,1,1,3]

  # set tensor dimensions (only used for determining contraction order)
  dims_dict = {'chi': chi, 'chimid': chimid}
  udim = ('chi','chi','chimid','chimid')
  wdim = ('chimid', 'chimid', 'chi')
  hdim = ('chi', 'chi', 'chi', 'chi', 'chi', 'chi')
  rhodim = ('chi', 'chi', 'chi', 'chi', 'chi', 'chi')
  symbolic_dims = [udim, udim, wdim, wdim, wdim, hdim, udim, udim, wdim, wdim, 
                  wdim, rhodim]
  numeric_dims = [[dims_dict[ele] for ele in tdim] for tdim in symbolic_dims]

  # define left principle diagram
  connectsL = [[3, 4, 10, 11], [7, 1, 12, 13], [8, 10, 21], [11, 12, 22],
              [13, 14, 23], [2, 5, 6, 3, 4, 7], [2, 5, 9, 17], [6, 1, 16, 15],
              [8, 9, 18], [17, 16, 19], [15, 14, 20], [18, 19, 20, 21, 22, 23]]
  coordsL = [(-0.5, 1), (0.5, 1), (-1, 2), (0, 2), (1, 2), (-0.4,-0.2,0.2,0.2), 
            (-0.5, -1), (0.5, -1), (-1, -2), (0, -2), (1, -2), (0.3)]
  orderL = solve_order(numeric_dims, connectsL)[0]

  # define right principle diagram
  connectsR = [[1, 3, 10, 11], [4, 7, 12, 13], [8, 10, 21], [11, 12, 22],
              [13, 14, 23], [2, 5, 6, 3, 4, 7], [1, 2, 9, 17], [5, 6, 16, 15],
              [8, 9, 18], [17, 16, 19], [15, 14, 20], [18, 19, 20, 21, 22, 23]]
  coordsR = [(-0.5, 1), (0.5, 1), (-1, 2), (0, 2), (1, 2), (-0.2,-0.2,0.4,0.2), 
            (-0.5, -1), (0.5, -1), (-1, -2), (0, -2), (1, -2), (0.3)]
  orderR = solve_order(numeric_dims, connectsR)[0]

  # draw_networks
  fig = plt.figure(figsize=(16,16))
  figL = draw_network(connectsL, coords=coordsL, names=names, colors=colors, 
                      order=orderL, title='Left principle diagram', 
                      draw_labels=False, show_costs=True, env_pad=(-0.2,-0.25),
                      legend_extend=3.0, fig=fig, subplot=121, 
                      dims=symbolic_dims)
  figR = draw_network(connectsR, coords=coordsR, names=names, colors=colors, 
                      order=orderR, title='Right principle diagram',  
                      draw_labels=False, show_costs=True, env_pad=(-0.2,-0.25),
                      legend_extend=3.0, fig=fig, subplot=122, 
                      dims=symbolic_dims)

  # Store `connects` and `order` in a dict for later use
  network_dict = {'connectsL': connectsL, 'orderL': orderL,
                  'connectsR': connectsR, 'orderR': orderR}

  return network_dict