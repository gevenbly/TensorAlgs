{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mod_binary_MERA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNI8HksnPHHIa/5EeEikTGu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gevenbly/TensorAlgs/blob/main/mod_binary_MERA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaUZRiK4bEwS"
      },
      "source": [
        "def expand_dims(tensor, new_dims):\n",
        "  \"\"\" \n",
        "  Expand the dims of a tensor by padding with zeros.\n",
        "  \"\"\"\n",
        "  old_dims = tensor.shape\n",
        "  dim_expand = [(old_dims[k], new_dims[k]) for k in range(tensor.ndim)]\n",
        "\n",
        "  return np.pad(tensor, dim_expand)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7aYAOQBiUZZ"
      },
      "source": [
        "def tprod(*tensor_list, do_matricize=True):\n",
        "  \"\"\" \n",
        "  Tensor product for operators. Expands the functionality of `kron` to accept \n",
        "  tensors rather than just matrices, and to accept and arbitrary number of \n",
        "  inputs. The index ordering is defined such that if the inputs are Hermtian \n",
        "  matrices the the output tensor can be reshaped into a Hermitian matrix.\n",
        "  \"\"\"\n",
        "  \n",
        "  # take kron of each input sequentially\n",
        "  shapes_L = []\n",
        "  shapes_R = []\n",
        "  final_tensor = np.array(1.0, dtype=float)\n",
        "  for tensor in tensor_list:\n",
        "    shapes_L = shapes_L + list(tensor.shape[:(tensor.ndim//2)])\n",
        "    shapes_R = shapes_R + list(tensor.shape[(tensor.ndim//2):])\n",
        "    final_tensor = np.kron(final_tensor, matricize(tensor))\n",
        "\n",
        "  if do_matricize:\n",
        "    return final_tensor\n",
        "  else:\n",
        "    return final_tensor.reshape(shapes_L + shapes_R)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9cZZ962KvQN"
      },
      "source": [
        "def matricize(tensor, partition=None):\n",
        "  \"\"\" Matricize an input tensor across some left/right partition. \"\"\"\n",
        "  \n",
        "  if partition is None:\n",
        "    partition = tensor.ndim // 2\n",
        "\n",
        "  size_L = np.prod(tensor.shape[:partition])\n",
        "  size_R = np.prod(tensor.shape[partition:])\n",
        " \n",
        "  return tensor.reshape(size_L, size_R)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn2qW8ihK9l_"
      },
      "source": [
        "def orthogonalize(tensor, partition=None):\n",
        "  \"\"\" Orthogonalize an input tensor across some left/right partition. \"\"\"\n",
        "\n",
        "  tshape = tensor.shape\n",
        "  ut, st, vt = LA.svd(matricize(tensor, partition=partition), \n",
        "                      full_matrices=False)\n",
        "\n",
        "  return (ut @ vt).reshape(tshape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCml5n60w2Dq"
      },
      "source": [
        "def define_ham(blocksize):\n",
        "  \"\"\" Define Hamiltonian (quantum critical Ising) \"\"\"\n",
        "\n",
        "  # define Pauli matrices\n",
        "  sX = np.array([[0, 1], [1, 0]], dtype=float)\n",
        "  sZ = np.array([[1, 0], [0, -1]], dtype=float)\n",
        "\n",
        "  # define Ising local Hamiltonian\n",
        "  ham_orig = (tprod(sX, sX) - 0.5*tprod(sZ, np.eye(2)) - \n",
        "              0.5*tprod(np.eye(2), sZ))\n",
        "\n",
        "  # shift Hamiltonian to ensure negative defined\n",
        "  en_shift = max(LA.eigh(ham_orig)[0])\n",
        "  ham_loc = ham_orig - en_shift*np.eye(4)\n",
        "\n",
        "  # define block Hamiltonians \n",
        "  d0 = 2 # initial local dim\n",
        "  d1 = d0**blocksize # local dim after blocking\n",
        "\n",
        "  if blocksize==3:\n",
        "    ham_block = (1.0*tprod(np.eye(d0**1), ham_loc, np.eye(d0**3)) + \n",
        "                 1.0*tprod(np.eye(d0**2), ham_loc, np.eye(d0**2)) +\n",
        "                 1.0*tprod(np.eye(d0**3), ham_loc, np.eye(d0**1))\n",
        "                 ).reshape(d0*np.ones(12, dtype=int))\n",
        "    hamAB_init = ham_block.transpose(0,1,2,5,4,3,6,7,8,11,10,9\n",
        "                                    ).reshape(d1, d1, d1, d1)\n",
        "    hamBA_init = ham_block.transpose(2,1,0,3,4,5,8,7,6,9,10,11\n",
        "                                    ).reshape(d1, d1, d1, d1)\n",
        "  elif blocksize==4:\n",
        "    ham_block = (0.5*tprod(np.eye(d0**1), ham_loc, np.eye(d0**5)) + \n",
        "                1.0*tprod(np.eye(d0**2), ham_loc, np.eye(d0**4)) + \n",
        "                1.0*tprod(np.eye(d0**3), ham_loc, np.eye(d0**3)) +\n",
        "                1.0*tprod(np.eye(d0**4), ham_loc, np.eye(d0**2)) +\n",
        "                0.5*tprod(np.eye(d0**5), ham_loc, np.eye(d0**1))\n",
        "                ).reshape(d0*np.ones(16, dtype=int))\n",
        "    hamAB_init = ham_block.transpose(0,1,2,3,7,6,5,4,8,9,10,11,15,14,13,12\n",
        "                                    ).reshape(d1, d1, d1, d1)\n",
        "    hamBA_init = ham_block.transpose(3,2,1,0,4,5,6,7,11,10,9,8,12,13,14,15\n",
        "                                    ).reshape(d1, d1, d1, d1)\n",
        "  \n",
        "  return hamAB_init, hamBA_init, en_shift"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N8zMmAKQYIJ"
      },
      "source": [
        "def initialize(chi, chimid, hamAB_init, hamBA_init):\n",
        "  \"\"\" Initialize the MERA tensors \"\"\"\n",
        "\n",
        "  # Initialize the MERA tensors\n",
        "  d1 = hamAB_init.shape[0]\n",
        "  iso_temp = orthogonalize(np.random.rand(d1, min(chimid, d1)))\n",
        "  uC = [tprod(iso_temp, iso_temp, do_matricize=False)]\n",
        "  wC = [orthogonalize(np.random.rand(d1, uC[0].shape[2], chi), partition=2)]\n",
        "  vC = [orthogonalize(np.random.rand(d1, uC[0].shape[2], chi), partition=2)]\n",
        "  for k in range(layers-1):\n",
        "    iso_temp = orthogonalize(np.random.rand(chi, chimid))\n",
        "    uC.append(tprod(iso_temp, iso_temp, do_matricize=False))\n",
        "    wC.append(orthogonalize(np.random.rand(chi, chimid, chi), partition=2))\n",
        "    vC.append(orthogonalize(np.random.rand(chi, chimid, chi), partition=2))\n",
        "  \n",
        "  # initialize density matrices and effective Hamiltonians\n",
        "  rhoAB = [0]\n",
        "  rhoBA = [0]\n",
        "  hamAB = [hamAB_init]\n",
        "  hamBA = [hamBA_init]\n",
        "  for k in range(layers):\n",
        "    rhoAB.append(np.eye((chi**2, chi**2)).reshape(chi, chi, chi, chi))\n",
        "    rhoBA.append(np.eye((chi**2, chi**2)).reshape(chi, chi, chi, chi))\n",
        "    hamAB.append(np.zeros((chi, chi, chi, chi)))\n",
        "    hamBA.append(np.zeros((chi, chi, chi, chi)))\n",
        "  \n",
        "  return hamAB, hamBA, wC, vC, uC, rhoAB, rhoBA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSLzMfwC6Jxy"
      },
      "source": [
        "def define_networks(hamAB, hamBA, wC, vC, uC, rhoAB, rhoBA):\n",
        "  \"\"\" Define and plot all principle networks \"\"\"\n",
        "\n",
        "  # Define the `M` principle network\n",
        "  connects_M = [[3,5,9], [1,5,7], [1,2,3,4], [4,6,10], [2,6,8], [7,8,9,10]]\n",
        "  tensors_M = [vC[1], vC[1], hamBA[1], wC[1], wC[1], rhoAB[2]]\n",
        "  order_M = ncon_solver(tensors_M, connects_M)[0]\n",
        "  dims_M = [tensor.shape for tensor in tensors_M]\n",
        "  names_M = ['v', 'v', 'hBA', 'w', 'w', 'rhoAB']\n",
        "  coords_M = [(-0.5,1),(-0.5,-1), (-0.3,-0.2,0.3,0.2),(0.5,1),(0.5,-1),(0.2)]\n",
        "  colors_M = [0,0,1,2,2,3]\n",
        "\n",
        "  # Define the `L` principle network\n",
        "  connects_L = [[3,6,13], [1,8,11], [4,5,6,7], [2,5,8,9], [1,2,3,4], \n",
        "                [10,7,14], [10,9,12], [11,12,13,14]]\n",
        "  tensors_L = [wC[1], wC[1], uC[1], uC[1], hamAB[1], vC[1], vC[1], rhoBA[2]]\n",
        "  order_L = ncon_solver(tensors_L, connects_L)[0]\n",
        "  dims_L = [tensor.shape for tensor in tensors_L]\n",
        "  names_L = ['w', 'w', 'u', 'u', 'hAB', 'v', 'v', 'rhoBA']\n",
        "  coords_L = [(-0.5, 1.5), (-0.5, -1.5), (-0.3,0.5,0.3,0.9), (-0.3,-0.5,0.3,-0.9), \n",
        "              (-0.6,-0.2,-0.1,0.2), (0.5, 1.5), (0.5, -1.5), (0.2)]\n",
        "  colors_L = [2,2,4,4,1,0,0,3]\n",
        "\n",
        "  # Define the `C` principle network\n",
        "  connects_C = [[5,6,13], [5,9,11], [3,4,6,8], [1,2,9,10], [1,2,3,4], [7,8,14],\n",
        "                [7,10,12], [11,12,13,14]]\n",
        "  tensors_C = [wC[1], wC[1], uC[1], uC[1], hamBA[1], vC[1], vC[1], rhoBA[2]]\n",
        "  order_C = ncon_solver(tensors_C, connects_C)[0]\n",
        "  dims_C = [tensor.shape for tensor in tensors_C]\n",
        "  names_C = ['w', 'w', 'u', 'u', 'hBA', 'v', 'v', 'rhoBA']\n",
        "  coords_C = [(-0.5, 1.5), (-0.5, -1.5), (-0.3,0.5,0.3,0.9), (-0.3,-0.5,0.3,-0.9), \n",
        "              (-0.3,-0.2,0.3,0.2), (0.5, 1.5), (0.5, -1.5), (0.2)]\n",
        "  colors_C = [2,2,4,4,1,0,0,3]\n",
        "\n",
        "  # Define the `R` principle network\n",
        "  connects_R = [[10,6,13], [10,8,11], [5,3,6,7], [5,1,8,9], [2,1,4,3], [4,7,14],\n",
        "                [2,9,12], [11,12,13,14]]\n",
        "  tensors_R = [wC[1], wC[1], uC[1], uC[1], hamAB[1], vC[1], vC[1], rhoBA[2]]\n",
        "  order_R = ncon_solver(tensors_R, connects_R)[0]\n",
        "  dims_R = [tensor.shape for tensor in tensors_R]\n",
        "  names_R = ['w', 'w', 'u', 'u', 'hAB', 'v', 'v', 'rhoBA']\n",
        "  coords_R = [(-0.5, 1.5), (-0.5, -1.5), (-0.3,0.5,0.3,0.9), (-0.3,-0.5,0.3,-0.9), \n",
        "              (0.6,-0.2,0.1,0.2), (0.5, 1.5), (0.5, -1.5), (0.2)]\n",
        "  colors_R = [2,2,4,4,1,0,0,3]\n",
        "\n",
        "  # Plot all principle networks\n",
        "  fig = plt.figure(figsize=(24,24))\n",
        "  figM = draw_network(connects_M, order=order_M, dims=dims_M, coords=coords_M, \n",
        "                      names=names_M, colors=colors_M, title='M-diagrams', \n",
        "                      draw_labels=False, show_costs=True, legend_extend=2.5, \n",
        "                      fig=fig, subplot=141, env_pad=(-0.4,-0.4))\n",
        "  figL = draw_network(connects_L, order=order_L, dims=dims_L, coords=coords_L, \n",
        "                      names=names_L, colors=colors_L, title='L-diagrams', \n",
        "                      draw_labels=False, show_costs=True, legend_extend=2.5, \n",
        "                      fig=fig, subplot=142, env_pad=(-0.4,-0.4))\n",
        "  figC = draw_network(connects_C, order=order_C, dims=dims_C, coords=coords_C, \n",
        "                      names=names_C, colors=colors_C, title='C-diagrams', \n",
        "                      draw_labels=False, show_costs=True, legend_extend=2.5, \n",
        "                      fig=fig, subplot=143, env_pad=(-0.4,-0.4))\n",
        "  figR = draw_network(connects_R, order=order_R, dims=dims_R, coords=coords_R, \n",
        "                      names=names_R, colors=colors_R, title='R-diagrams', \n",
        "                      draw_labels=False, show_costs=True, legend_extend=2.5, \n",
        "                      fig=fig, subplot=144, env_pad=(-0.4,-0.4))\n",
        "\n",
        "  # Store `connects` and `order` in a dict for later use\n",
        "  network_dict = {'connects_M': connects_M, 'order_M': order_M,\n",
        "                  'connects_L': connects_L, 'order_L': order_L,\n",
        "                  'connects_C': connects_C, 'order_C': order_C,\n",
        "                  'connects_R': connects_R, 'order_R': order_R,}\n",
        "\n",
        "  return network_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec3x6ITl7qrv"
      },
      "source": [
        "def lift_hamiltonian(hamAB, hamBA, w, v, u, rhoAB, rhoBA, network_dict):\n",
        "  \"\"\" Lift the Hamiltonian through one MERA layer \"\"\"\n",
        "\n",
        "  hamAB_lift = xcon([v, v, hamBA, w, w, rhoAB], \n",
        "                    network_dict['connects_M'], \n",
        "                    order=network_dict['order_M'], which_envs=5)\n",
        "\n",
        "  hamBA_temp0 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                     network_dict['connects_L'], \n",
        "                     order=network_dict['order_L'], which_envs=7)\n",
        "\n",
        "  hamBA_temp1 = xcon([w, w, u, u, hamBA, v, v, rhoBA], \n",
        "                     network_dict['connects_C'], \n",
        "                     order=network_dict['order_C'], which_envs=7)\n",
        "\n",
        "  hamBA_temp2 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                     network_dict['connects_R'], \n",
        "                     order=network_dict['order_R'], which_envs=7)\n",
        "  \n",
        "  hamBA_lift = hamBA_temp0 + hamBA_temp1 + hamBA_temp2\n",
        "\n",
        "  return hamAB_lift, hamBA_lift"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt89CEM2NS2y"
      },
      "source": [
        "def lower_density(hamAB, hamBA, w, v, u, rhoAB, rhoBA, network_dict):\n",
        "  \"\"\" Lower the density matrix through one MERA layer \"\"\"\n",
        "\n",
        "  rhoBA_temp0 = xcon([v, v, hamBA, w, w, rhoAB], \n",
        "                     network_dict['connects_M'], \n",
        "                     order=network_dict['order_M'], which_envs=2)\n",
        "\n",
        "  rhoAB_temp0 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                     network_dict['connects_L'], \n",
        "                     order=network_dict['order_L'], which_envs=4)\n",
        "\n",
        "  rhoBA_temp1 = xcon([w, w, u, u, hamBA, v, v, rhoBA], \n",
        "                     network_dict['connects_C'], \n",
        "                     order=network_dict['order_C'], which_envs=4)\n",
        "  \n",
        "  rhoAB_temp1 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                     network_dict['connects_R'], \n",
        "                     order=network_dict['order_R'], which_envs=4)\n",
        "  \n",
        "  rhoAB_lower = 0.5*(rhoAB_temp0 + rhoAB_temp1)\n",
        "  rhoBA_lower = 0.5*(rhoBA_temp0 + rhoBA_temp1)\n",
        "\n",
        "  return rhoAB_lower, rhoBA_lower"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48kn9l27ONxp"
      },
      "source": [
        "def optimize_w(hamAB, hamBA, w, v, u, rhoAB, rhoBA, network_dict):\n",
        "  \"\"\" Optimise the `w` isometry \"\"\"\n",
        "\n",
        "  w_env0 = xcon([v, v, hamBA, w, w, rhoAB], network_dict['connects_M'], \n",
        "                order=network_dict['order_M'], which_envs=3)\n",
        "  \n",
        "  w_env1 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                network_dict['connects_L'], order=network_dict['order_L'], \n",
        "                which_envs=0)\n",
        "  \n",
        "  w_env2 = xcon([w, w, u, u, hamBA, v, v, rhoBA], \n",
        "                network_dict['connects_C'], order=network_dict['order_C'], \n",
        "                which_envs=0)\n",
        "  \n",
        "  w_env3 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                network_dict['connects_R'], order=network_dict['order_R'], \n",
        "                which_envs=0)\n",
        "  \n",
        "  w_out = orthogonalize(w_env0 + w_env1 + w_env2 + w_env3, partition=2)\n",
        "\n",
        "  return w_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di3CNfrxZWoQ"
      },
      "source": [
        "def optimize_v(hamAB, hamBA, w, v, u, rhoAB, rhoBA, network_dict):\n",
        "  \"\"\" Optimise the `v` isometry \"\"\"\n",
        "\n",
        "  v_env0 = xcon([v, v, hamBA, w, w, rhoAB], network_dict['connects_M'], \n",
        "                order=network_dict['order_M'], which_envs=0)\n",
        "  \n",
        "  v_env1 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                network_dict['connects_L'], order=network_dict['order_L'], \n",
        "                which_envs=5)\n",
        "  \n",
        "  v_env2 = xcon([w, w, u, u, hamBA, v, v, rhoBA], \n",
        "                network_dict['connects_C'], order=network_dict['order_C'], \n",
        "                which_envs=5)\n",
        "  \n",
        "  v_env3 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                network_dict['connects_R'], order=network_dict['order_R'], \n",
        "                which_envs=5)\n",
        "  \n",
        "  v_out = orthogonalize(v_env0 + v_env1 + v_env2 + v_env3, partition=2)\n",
        "\n",
        "  return v_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGciWMuaZXUB"
      },
      "source": [
        "def optimize_u(hamAB, hamBA, w, v, u, rhoAB, rhoBA, network_dict):\n",
        "  \"\"\" Optimise the `w` isometry \"\"\"\n",
        "  \n",
        "  u_env0 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                network_dict['connects_L'], order=network_dict['order_L'], \n",
        "                which_envs=2)\n",
        "  \n",
        "  u_env1 = xcon([w, w, u, u, hamBA, v, v, rhoBA], \n",
        "                network_dict['connects_C'], order=network_dict['order_C'], \n",
        "                which_envs=2)\n",
        "  \n",
        "  u_env2 = xcon([w, w, u, u, hamAB, v, v, rhoBA], \n",
        "                network_dict['connects_R'], order=network_dict['order_R'], \n",
        "                which_envs=2)\n",
        "  \n",
        "  u_out = orthogonalize(u_env0 + u_env1 + u_env2, partition=2)\n",
        "\n",
        "  return u_out"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}