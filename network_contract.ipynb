{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "network_contract.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRSTWG+Fi+Hr98mvbpMVEa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOEugbeTVZ3m"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT89MyRMowSy"
      },
      "source": [
        "# Test example\n",
        "connects = [[4, 5, 10, 11], [6, 7, 12, 13], [8, 10, -4], [11, 12, -5],\n",
        "            [13, 14, -6], [1, 2, 3, 4, 5, 6], [1, 2, 9, 17], [3, 7, 16, 15],\n",
        "            [8, 9, -1], [17, 16, -2], [15, 14, -3]]\n",
        "pt_cont, bn_cont, pt_costs, bn_costs = pre_ncon(connects)\n",
        "print(pt_costs)\n",
        "print(bn_costs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOQc6iuqxQUM"
      },
      "source": [
        "def pre_ncon(connects, dims=None, order=None):\n",
        "  \"\"\" \n",
        "  Identify the labels involved in each tensor contraction (either a partial \n",
        "  trace or a binary tensor contraction).\n",
        "  \"\"\"\n",
        "  # define default dims everywhere as `d`\n",
        "  if dims is None:\n",
        "    dims = []\n",
        "    for tensor in connects:\n",
        "      dims.append(['d'] * len(tensor))\n",
        "\n",
        "  # build dictionary between original and canonical dims\n",
        "  nml_dims, fwd_dim_dict, rev_dim_dict = make_cannon_dims(dims)\n",
        "\n",
        "  # build dictionary between original and canonical labels\n",
        "  nml_connects, fwd_dict, rev_dict, npos, nneg = make_cannon_connects(connects)\n",
        "\n",
        "  # find canonical order\n",
        "  if order is None:\n",
        "    nml_order = np.arange(npos) + 1\n",
        "  else:\n",
        "    nml_order = np.array([fwd_dict[ele] for ele in order])\n",
        "\n",
        "  # check validity of network\n",
        "  check_inputs(nml_connects, nml_dims, nml_order, rev_dict, rev_dim_dict)\n",
        "\n",
        "  # identify contraction indices\n",
        "  pt_cont, bn_cont = identify_cont_labels(nml_connects, nml_order)\n",
        "\n",
        "  # compute contraction costs\n",
        "  pt_costs, bn_costs = compute_costs(nml_connects, nml_dims, pt_cont, bn_cont, \n",
        "                                     rev_dim_dict)\n",
        "    \n",
        "  return pt_cont, bn_cont, pt_costs, bn_costs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP4sTameHvgi"
      },
      "source": [
        "def compute_costs(connects, dims, pt_cont, bn_cont, rev_dim_dict):\n",
        "  \"\"\" \n",
        "  Identify the labels involved in each tensor contraction (either a partial \n",
        "  trace or a binary tensor contraction).\n",
        "  \"\"\"\n",
        "  nml_connects = [ele for ele in connects]\n",
        "  nml_dims = [ele for ele in dims]\n",
        "\n",
        "  # partial trace costs\n",
        "  pt_costs = []\n",
        "  for pt_labs in pt_cont:\n",
        "    for count, sublist in enumerate(nml_connects):\n",
        "      pt_inds, pt_locs0, _ = np.intersect1d(sublist, pt_labs, return_indices=True)\n",
        "      if len(pt_inds) > 0:\n",
        "        sublist = np.delete(sublist, pt_locs0)\n",
        "        cont_cost = np.delete(nml_dims[count], pt_locs0)\n",
        "        _, pt_locs1, _ = np.intersect1d(sublist, pt_labs, return_indices=True)\n",
        "        \n",
        "        nml_connects[count] = np.delete(sublist, pt_locs1)\n",
        "        nml_dims[count] = np.delete(cont_cost, pt_locs1)\n",
        "        break\n",
        "    \n",
        "    pt_costs.append(cont_cost)\n",
        "\n",
        "  # binary contraction costs\n",
        "  bn_costs = []\n",
        "  for bn_labs in bn_cont:\n",
        "    locs = [ele for ele in range(len(nml_connects)) if \n",
        "            sum(nml_connects[ele] == bn_labs[0]) > 0]\n",
        "    cont_many, A_cont, B_cont = np.intersect1d(\n",
        "        nml_connects[locs[0]],\n",
        "        nml_connects[locs[1]],\n",
        "        assume_unique=True,\n",
        "        return_indices=True)\n",
        "\n",
        "    nml_connects.append(np.concatenate((\n",
        "        np.delete(nml_connects[locs[0]], A_cont),\n",
        "        np.delete(nml_connects[locs[1]], B_cont))))\n",
        "    bn_costs.append(np.concatenate((\n",
        "        np.delete(nml_dims[locs[0]], A_cont), nml_dims[locs[1]])))\n",
        "    nml_dims.append(np.concatenate((\n",
        "        np.delete(nml_dims[locs[0]], A_cont),\n",
        "        np.delete(nml_dims[locs[1]], B_cont))))\n",
        "\n",
        "    del nml_connects[locs[1]]\n",
        "    del nml_connects[locs[0]]\n",
        "    del nml_dims[locs[1]]\n",
        "    del nml_dims[locs[0]]\n",
        "\n",
        "  # tally the total partial trace costs\n",
        "  is_symbolic = False\n",
        "  int_pt_costs = []\n",
        "  fin_pt_costs = []\n",
        "  for cost in pt_costs:\n",
        "    uni_dims = np.unique(cost)\n",
        "\n",
        "    str_cost = ''\n",
        "    int_cost = 1\n",
        "    for dim in uni_dims:\n",
        "      degen = sum(cost == dim)\n",
        "      value = rev_dim_dict[dim]\n",
        "\n",
        "      if isinstance(value, str):\n",
        "        str_cost += '(' + value + '^' + str(degen) + ')'\n",
        "        is_symbolic = True\n",
        "      elif isinstance(value, int):\n",
        "        int_cost = int_cost * value**degen\n",
        "\n",
        "    int_pt_costs.append(int_cost)\n",
        "    fin_pt_costs.append(str(int_cost) + '*' + str_cost)\n",
        "\n",
        "  # tally the total binary contraction costs\n",
        "  int_bn_costs = []\n",
        "  fin_bn_costs = []\n",
        "  for cost in bn_costs:\n",
        "    uni_dims = np.unique(cost)\n",
        "\n",
        "    str_cost = ''\n",
        "    int_cost = 1\n",
        "    for dim in uni_dims:\n",
        "      degen = sum(cost == dim)\n",
        "      value = rev_dim_dict[dim]\n",
        "\n",
        "      if isinstance(value, str):\n",
        "        str_cost += '(' + value + '^' + str(degen) + ')'\n",
        "        is_symbolic = True\n",
        "      elif isinstance(value, int):\n",
        "        int_cost = int_cost * value**degen\n",
        "\n",
        "    int_bn_costs.append(int_cost)\n",
        "    fin_bn_costs.append(str(int_cost) + '*' + str_cost)\n",
        "\n",
        "  if not is_symbolic:\n",
        "    fin_pt_costs = int_pt_costs\n",
        "    fin_bn_costs = int_bn_costs\n",
        "\n",
        "  return fin_pt_costs, fin_bn_costs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErFGJMyZ17vB"
      },
      "source": [
        "def identify_cont_labels(connects, order):\n",
        "  \"\"\" \n",
        "  Identify the labels involved in each tensor contraction (either a partial \n",
        "  trace or a binary tensor contraction).\n",
        "  \"\"\"\n",
        "\n",
        "  nml_order = [ele for ele in order]\n",
        "  nml_connects = [ele for ele in connects]\n",
        "\n",
        "  # indentify partial trace indices to be contracted\n",
        "  pt_cont = []\n",
        "  for count, sublist in enumerate(nml_connects):\n",
        "    uni_labs, uni_locs = np.unique(sublist, return_index=True)\n",
        "    # uni_dims = [tensor_dims[count][loc] for loc in uni_locs]\n",
        "    num_cont = len(sublist) - len(uni_labs)\n",
        "    if num_cont > 0:\n",
        "      dup_list = []\n",
        "      for ele in uni_labs:\n",
        "        temp_locs = np.where(sublist == ele)[0]\n",
        "        if len(temp_locs) == 2:\n",
        "          dup_list.append(ele)\n",
        "          sublist = np.delete(sublist, temp_locs)\n",
        "          nml_order = np.delete(nml_order, nml_order==ele)\n",
        "      \n",
        "      pt_cont.append(np.array(dup_list))\n",
        "      nml_connects[count] = sublist\n",
        "\n",
        "  # indentify binary contraction indices \n",
        "  bn_cont = []\n",
        "  while len(nml_order) > 0:\n",
        "    locs = [ele for ele in range(len(nml_connects)) \n",
        "            if sum(nml_connects[ele] == nml_order[0]) > 0]\n",
        "\n",
        "    cont_many, A_cont, B_cont = np.intersect1d(\n",
        "        nml_connects[locs[0]],\n",
        "        nml_connects[locs[1]],\n",
        "        assume_unique=True,\n",
        "        return_indices=True)\n",
        "    \n",
        "    bn_cont.append(cont_many)\n",
        "    nml_connects.append(np.concatenate((\n",
        "      np.delete(nml_connects[locs[0]], A_cont),\n",
        "      np.delete(nml_connects[locs[1]], B_cont))))\n",
        "    del nml_connects[locs[1]]\n",
        "    del nml_connects[locs[0]]\n",
        "    nml_order = np.delete(nml_order, np.intersect1d(nml_order, \n",
        "                                                    cont_many, \n",
        "                                                    return_indices=True)[1])\n",
        "    \n",
        "  return pt_cont, bn_cont"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekYqe5uX2Its"
      },
      "source": [
        "def make_cannon_dims(dims):\n",
        "  \"\"\" \n",
        "  Create dict holding the unique tensor dims, which may be input either as \n",
        "  strings or integers, and transform the dims according to this dict. \n",
        "  \"\"\"\n",
        "  \n",
        "  # flatten the list of connections\n",
        "  flat_dims = [item for sublist in dims for item in sublist]\n",
        "\n",
        "  # find unique entries\n",
        "  uni_dims = []\n",
        "  for ele in flat_dims:\n",
        "    if ele not in uni_dims:\n",
        "      uni_dims.append(ele)\n",
        "  \n",
        "  # create dictionary to map between original and cannonical dims\n",
        "  fwd_dict = dict(zip(uni_dims, np.arange(len(uni_dims))))\n",
        "  rev_dict = dict(zip(np.arange(len(uni_dims)), uni_dims))\n",
        "\n",
        "  # make canonical dims\n",
        "  can_dims = []\n",
        "  for tensor in dims:\n",
        "    temp_dims = []\n",
        "    for lab in tensor:\n",
        "      temp_dims.append(fwd_dict[lab])\n",
        "    can_dims.append(np.array(temp_dims, dtype=int))\n",
        "\n",
        "  return can_dims, fwd_dict, rev_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BmTxuZ9H19q"
      },
      "source": [
        "def make_cannon_connects(connects):\n",
        "  \"\"\"\n",
        "  Takes in a set of `connects` defining a network, where index labels can be\n",
        "  given either as `int` or `str` and returns dicts mapping between cannonical\n",
        "  labels: where open (external) indices are labelled with negative integers \n",
        "  (starting at -1) and closed (internal) indices are labelled with positive\n",
        "  integers (starting at +1). Sorting of indices is done alpha-numerically.\n",
        "  \"\"\"\n",
        "\n",
        "  # flatten the list of connections\n",
        "  flat_connects = [item for sublist in connects for item in sublist]\n",
        "\n",
        "  # separate ints from strs\n",
        "  int_connects = []\n",
        "  str_connects = []\n",
        "  for ele in flat_connects:\n",
        "    if isinstance(ele, int):\n",
        "      int_connects.append(ele)\n",
        "    elif isinstance(ele, str):\n",
        "      str_connects.append(ele)\n",
        "\n",
        "  # separate single (open) indices from double (closed) indices\n",
        "  sgl_str = []\n",
        "  dbl_str = []\n",
        "  for ele in str_connects:\n",
        "    if str_connects.count(ele) == 1:\n",
        "      sgl_str.append(ele)\n",
        "    elif str_connects.count(ele) == 2:\n",
        "      if dbl_str.count(ele) == 0:\n",
        "        dbl_str.append(ele)\n",
        "    else:\n",
        "      raise ValueError(\"index label {ind} is repeated more than twice\".format(\n",
        "          ind = \"`\" + ele + \"`\"))\n",
        "\n",
        "  sgl_int = []\n",
        "  dbl_int = []\n",
        "  for ele in int_connects:\n",
        "    if int_connects.count(ele) == 1:\n",
        "      sgl_int.append(ele)\n",
        "    elif int_connects.count(ele) == 2:\n",
        "      if dbl_int.count(ele) == 0:\n",
        "        dbl_int.append(ele)\n",
        "    else:\n",
        "      raise ValueError(\"index label {ind} is repeated more than twice\".format(\n",
        "          ind = \"`\" + str(ele) + \"`\"))\n",
        "  \n",
        "  # sort and combine index labels\n",
        "  sgl_str.sort()\n",
        "  dbl_str.sort()\n",
        "  sgl_int.sort()\n",
        "  sgl_int.reverse()\n",
        "  dbl_int.sort()\n",
        "  open_inds = sgl_str + sgl_int\n",
        "  clsd_inds = dbl_str + dbl_int\n",
        "  num_neg = len(open_inds)\n",
        "  num_pos = len(clsd_inds)\n",
        "  \n",
        "  # create dictionary to map between original and cannonical labels\n",
        "  pos_labs = dict(zip(open_inds, -np.arange(1,len(open_inds) + 1)))\n",
        "  neg_labs = dict(zip(clsd_inds, np.arange(1,len(clsd_inds) + 1)))\n",
        "  can_labs = {**pos_labs, **neg_labs}\n",
        "  rev_can_labs = dict(zip(can_labs.values(), can_labs.keys()))\n",
        "\n",
        "  # make canonical connections\n",
        "  can_connects = []\n",
        "  for tensor in connects:\n",
        "    temp_inds = []\n",
        "    for lab in tensor:\n",
        "      temp_inds.append(can_labs[lab])\n",
        "    can_connects.append(np.array(temp_inds, dtype=int))\n",
        "\n",
        "  return can_connects, can_labs, rev_can_labs, num_pos, num_neg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFRdisfM6te2"
      },
      "source": [
        "def check_inputs(connects, dims, con_order, rev_dict, rev_dim_dict):\n",
        "  \"\"\" Check consistancy of NCON inputs\"\"\"\n",
        "\n",
        "  flat_connect = np.concatenate(connects)\n",
        "  pos_ind = flat_connect[flat_connect > 0]\n",
        "  neg_ind = flat_connect[flat_connect < 0]\n",
        "\n",
        "  # check that lengths of lists match\n",
        "  if len(dims) != len(connects):\n",
        "    raise ValueError((\n",
        "        'Network definition error: mismatch between {n0} tensors given but {n1}'\n",
        "        ' index sublists given'.format(n0 = str(len(dims)), \n",
        "                                       n1 = str(len(connects)))))\n",
        "\n",
        "  # check that tensors have the right number of indices\n",
        "  for ele in range(len(dims)):\n",
        "    if len(dims[ele]) != len(connects[ele]):\n",
        "      raise ValueError(\n",
        "          'Network definition error: number of indices does not match number'\n",
        "          ' of labels on tensor {n0}: {n1}-indices versus {n2}-labels'.format(\n",
        "              n0 = str(ele),\n",
        "              n1 = str(len(dims[ele])),\n",
        "              n2 = str(len(connects[ele]))))\n",
        "\n",
        "  # check that contraction order is valid\n",
        "  if not np.array_equal(np.sort(con_order), np.unique(pos_ind)):\n",
        "    print(np.sort(con_order))\n",
        "    print(np.unique(pos_ind))\n",
        "    raise ValueError('Network definition error: invalid contraction order')\n",
        "\n",
        "  # check that positive indices are valid and contracted tensor dimensions match\n",
        "  flat_dims = np.array([item for sublist in dims for item in sublist])\n",
        "  for ind in np.unique(pos_ind):\n",
        "    if sum(pos_ind == ind) == 1:\n",
        "      raise ValueError(\n",
        "        'Network definition error: only one index labelled {n0}'\n",
        "        .format(n0 = \"`\" + str(rev_dict[ind]) + \"`\"))\n",
        "    elif sum(pos_ind == ind) > 2:\n",
        "      raise ValueError(\n",
        "        'Network definition error: more than two indices labelled {n0}'\n",
        "        .format(n0 = \"`\" + str(rev_dict[ind]) + \"`\"))\n",
        "\n",
        "    cont_dims = flat_dims[flat_connect == ind]\n",
        "    if cont_dims[0] != cont_dims[1]:\n",
        "      raise ValueError(\n",
        "          'Network definition error: tensor dimension mismatch on'\n",
        "          ' index labelled {n0}: dim-{n1} versus dim-{n2}'\n",
        "          .format(n0 = \"`\" + str(rev_dict[ind]) + \"`\", \n",
        "                  n1 = str(rev_dim_dict[cont_dims[0]]), \n",
        "                  n2 = str(rev_dim_dict[cont_dims[1]])))\n",
        "\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}