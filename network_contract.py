# -*- coding: utf-8 -*-
"""network_contract.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KtK3SZtGr_4uLaIhf7_Y_w_Kv0MUDojc
"""

import numpy as np
from typing import Optional, List, Union, Tuple
from network_solve import call_solver
from network_helpers import intersect_lists


def find_nodes(connects, order, dims=None):
  """ 
  Find the node ordering of a network.
  """
  tot_cost = np.uint64(0);
  tconnects = [connect for connect in connects]
  torder = [ele for ele in order]
  
  N = len(tconnects) 
  temp_nodes = np.zeros(3, dtype=np.uint64)
  nodes = np.zeros((N-2, 3), dtype=np.uint64)
  node_labs = [np.uint64(2**k) for k in range(N)]
  for count in range(N-2):
    locs = [ele for ele in range(len(tconnects)) if 
            torder[0] in tconnects[ele]]
    
    conA = tconnects.pop(locs[1])
    conB = tconnects.pop(locs[0])
    cont_many, A_cont, B_cont, conC = intersect_lists(conA, conB)
    tconnects.append(conC)

    temp_nodes[0] = node_labs[locs[0]]
    temp_nodes[1] = node_labs[locs[1]]
    temp_nodes[2] = 2**N - node_labs[locs[0]] - node_labs[locs[1]] - 1
    nodes[count, :] = np.sort(temp_nodes)

    # compute contraction costs
    if dims is not None:
      shp0 = np.prod([dim for k, dim in enumerate(dims[locs[1]]) 
                      if k not in A_cont], dtype=np.uint64)
      shp1 = np.prod(dims[locs[0]], dtype=np.uint64)
      tot_cost += shp0 * shp1
    
    if dims is not None:
      dimA = dims.pop(locs[1])
      dimA = [dim for k, dim in enumerate(dimA) if k not in A_cont ]
      dimB = dims.pop(locs[0])
      dimB = [dim for k, dim in enumerate(dimB) if k not in B_cont ]
      dims.append(list(dimA) + list(dimB))
      
    node_labs = np.append(node_labs, node_labs[locs[0]] + node_labs[locs[1]])
    node_labs = np.delete(node_labs, [locs[0], locs[1]])

    torder = [lab for lab in torder if lab not in cont_many]

  return nodes, tot_cost


def node_to_order(connects_in, nodes, which_env):
  """
  Produces a contraction order from the connects and nodes for the network with
  tensor at `which_env` held vacant. Used in `ncon_remove`.
  """

  N = len(connects_in)
  connects = [connect for connect in connects_in]
  del connects[which_env]

  # initialize nodes
  nodes_poss = [np.uint64(2**k) for k in range(N) if k != which_env]
  nodes_remain = list(range(N-2))
  order = []
  for k in range(N-2):
    for p, pos in enumerate(nodes_remain):
      # find nodes that are able to be contracted
      nodes_avail = [node for node in nodes[pos,:] if node in nodes_poss]
      if len(nodes_avail) == 2:
        loc = [nodes_poss.index(node) for node in nodes_avail]
        ord_temp, loc0, loc1, conC = intersect_lists(
          connects[loc[0]], connects[loc[1]])
        order += list(ord_temp)
        connects.append(conC)
        
        # update list of possessed nodes
        nodes_poss.append(np.uint64(sum(nodes_avail)))
        del nodes_remain[p]       
        break

  return order


def solve_order(tensors: List[np.ndarray],
                connects: List[List[int]],
                max_branch: Optional[int] = None,
                order: Optional[List[int]] = None):
  """
  Solve for the contraction order of a tensor network (encoded in the `ncon`
  syntax) that minimizes the computational cost.
  Args:
    tensors: list of the tensors in the network.
    connects: list of the tensor connections (in standard `ncon` format).
    max_branch: maximum number of contraction paths to search at each step.
  Returns:
    np.ndarray: the cheapest contraction order found (in ncon format).
    float: the cost of the network contraction, given as log10(total_FLOPS).
    bool: specifies if contraction order is guaranteed optimal.
  """
  return call_solver(tensors, connects, max_branch=max_branch, order=order)

def xcon(tensors_in, connects_in, order=None, open_order=None, which_envs=None, 
         perform_check=False, return_info=False, solver=None):
  """ 
  Xtreme CONtractor: Upgrades `ncon` in numerous ways, including (i) support
  for network labels as strings, (ii) incorporation auto-differentiation to 
  determine the single tensor environments, (iii) incorporation of a solver to
  find the optimal contraction order. Uses smart recycling of intermediate 
  tensors when computing multiple enviornments simultaneously, allowing for 
  a more efficient evaluation as compared to evaluating each environment 
  separately. 
  """
  # duplicate input lists
  tensors = [tensor for tensor in tensors_in]
  connects = [connect for connect in connects_in]

  # deal with single environment case separately
  if isinstance(which_envs,list):
    if len(which_envs) == 1:
      which_envs = which_envs[0]
  if isinstance(which_envs, int):
    # generate new connects and order for network with vacancy
    connects_new, order_new, open_ord = remove_tensor(
        connects, which_envs, order=order)

    # contract network with vacancy
    del tensors[which_envs]
    return xcon(tensors, connects_new, order=order_new, 
                perform_check=perform_check, return_info=return_info, 
                solver=solver, open_order=open_order)
  
  # generate contraction order if necessary
  if order is None:
    flat_connect = [item for sublist in connects for item in sublist]
    order_new = [ele for k, ele in enumerate(flat_connect) if 
                 ele in flat_connect[(k+1):]]
  else:
    order_new = [ele for ele in list(order)]

  # check validity of network
  if perform_check:
    dims = [tensor.shape for tensor in tensors]
    check_network(connects, dims, order_new)

  # solve for optimal contraction order
  if solver is not None:
    if solver == 'greedy':
      max_branch = 1
    elif solver == 'full':
      max_branch = None
    elif isinstance(solver, int):
      max_branch = solver
    order_new = solve_order(tensors, connects, max_branch, order=order_new)[0]

  # use simple contraction scheme if envs are not required
  if which_envs is None:
    return ncon(tensors, connects, order=order_new, perform_check=False,
                return_info=return_info, open_order=open_order)

  # do all partial traces
  tot_cost = np.uint64(0)
  for k, connect in enumerate(connects):
    cont_inds = [ele for p, ele in enumerate(connects) if 
                 ele in connect[(p+1):]]
    if len(cont_inds) > 0:
      tensors[k], connects[k], cost = partial_trace(
          connects[k], tensor=tensors[k], cont_inds=cont_inds)
      order_new = [order for order in order_new if order not in cont_inds]
      tot_cost += cost
      
  # find node representation of contraction
  N = len(connects)
  dims = [np.array(tensor.shape, dtype=int) for tensor in tensors]
  nodes, temp_cost = find_nodes(connects, order_new, dims=dims)
  tot_cost += temp_cost
  node_labs, needed_conts = reorder_nodes(nodes, which_envs)
  
  init_nodes = [np.uint64(2**k) for k in range(N)]
  temp_locs = [k for k, lab in enumerate(node_labs) if k in init_nodes]
  common_nodes, temp_locs = intersect_lists(node_labs, init_nodes)[:2]
  
  init_locs = intersect_lists(common_nodes, init_nodes)[2]
  nodes_occupied = np.zeros(len(node_labs), dtype=int)
  nodes_occupied[temp_locs] = np.ones(len(temp_locs))

  # expand lists to include room for intermediate tensors
  tensors_all = [np.zeros(0)] * len(node_labs)
  connects_all = [0] * len(node_labs)
  
  for count, loc in enumerate(temp_locs):
    tensors_all[loc] = tensors[init_locs[count]]
    connects_all[loc] = connects[init_locs[count]]
  
  tensors_all, connects_all, node_labs = (
      do_node_contracts(tensors_all, connects_all, nodes, needed_conts, 
                        node_labs, nodes_occupied))
  env_order = np.array([(2**N - 2**env - 1) for env in which_envs], 
                        dtype=np.uint64)
  env_perm = [np.where(node_labs==env)[0].item() for env in env_order]
  all_perms = []
  for k in range(len(which_envs)):
    temp_connect0 = connects_all[env_perm[k]]
    temp_connect1 = connects[which_envs[k]]
    perm_temp = [temp_connect0.index(ele) for ele in temp_connect1] 
    all_perms.append(perm_temp)
    
  tensors_all[:] = [np.transpose(tensors_all[env_perm[k]], all_perms[k]) for 
                    k in range(len(env_perm))]
  
  if return_info:
    return tensors_all, order_new, tot_cost
  else:
    return tensors_all

def ncon(tensors:       List[np.ndarray],
         connects:      List[Union[List[int], Tuple[int]]],
         order:         Optional[Union[List[int], List[str]]] = None,
         open_order:    Optional[Union[List[int], List[str]]] = None,
         perform_check: Optional[bool] = True,
         return_info:   Optional[bool] = False):
  """
  Network CONtractor: contracts a tensor network of N tensors via a sequence
  of (N-1) tensordot operations. More detailed instructions and examples can
  be found at: https://arxiv.org/abs/1402.0939.
  Args:
    tensors: list of the tensors in the network.
    connects: length-N list of lists (or tuples) specifying the network
      connections. The jth entry of the ith list in connects labels the edge
      connected to the jth index of the ith tensor. Labels should be positive
      integers for internal indices and negative integers for free indices.
    order: optional argument to specify the order for contracting the
      positive indices. Defaults to ascending order if omitted. Can also be
      set at "greedy" or "full" to call a solver to automatically determine
      the order.
    open_order: specification for the index ordering of the output tensor 
      (overrides the standard convention of descending order on -ve labels).
    perform_check: if true then the input network is checked for consistency;
      this can catch many common user mistakes for defining networks.
    return info: if true then return the contraction `order` and `cost`.
    
  Returns:
    Union[np.ndarray,float]: the result of the network contraction; an
      np.ndarray if the network contained open indices, otherwise a scalar.
  """
  tot_cost = np.uint64(0)
  num_tensors = len(tensors)
  tensor_list = [tensors[ele] for ele in range(num_tensors)]
  connect_list = [connects[ele] for ele in range(num_tensors)]

  # generate contraction order if necessary
  if order is None:
    flat_connect = [item for sublist in connect_list for item in sublist]
    order_new = [ele for k, ele in enumerate(flat_connect) if 
                 ele in flat_connect[(k+1):]]
  else:
    order_new = [ele for ele in list(order)]

  # check inputs if enabled
  if perform_check:
    dims_list = [list(tensor.shape) for tensor in tensor_list]
    check_network(connect_list, dims_list, order_new)

  # do all partial traces
  for k, connect in enumerate(connect_list):
    cont_inds = [ele for p, ele in enumerate(connect) if 
                 ele in connect[(p+1):]]
    if len(cont_inds) > 0:
      tensor_list[k], connect_list[k], cost = partial_trace(
          connect_list[k], tensor=tensor_list[k], cont_inds=cont_inds)
      order_new = [order for order in order_new if order not in cont_inds]
      tot_cost += cost

  # do all binary contractions
  order_new = list(order_new)
  
  while len(order_new) > 0:
    # identify tensors to be contracted
    locs = [k for k, connect in enumerate(connect_list) if 
            order_new[0] in connect]
    tensorA = tensor_list.pop(locs[1])
    tensorB = tensor_list.pop(locs[0])
    connectA = list(connect_list.pop(locs[1]))
    connectB = list(connect_list.pop(locs[0]))
  
    # identify indices to be contracted
    common, locsA, locsB, connectC = intersect_lists(connectA, connectB)

    if return_info:
      # compute contraction costs
      tot_cost += np.uint64(tensorA.size) * np.prod(
        [ele for k, ele in enumerate(tensorB.shape) if k not in locsB], 
        dtype=np.uint64)

    # do binary contraction using tensordot
    tensor_list.append(np.tensordot(tensorA, tensorB, axes=(locsA, locsB)))
    connect_list.append(connectC)
    order_new = [order for order in order_new if order not in common]
    
  # do all outer products
  while len(tensor_list) > 1:
    tensorA = tensor_list.pop(-1)
    tensorB = tensor_list.pop(-1)
    connectA = connect_list.pop(-1)
    connectB = connect_list.pop(-1)
    s1 = tensorA.shape
    s2 = tensorB.shape

    if return_info:
      tot_cost += np.uint64(np.prod(s1)*np.prod(s2))
      
    tensor_list.append(
      np.outer(tensorA.reshape(np.prod(s1)),
               tensorB.reshape(np.prod(s2))).reshape(np.append(s1, s2)))
    connect_list.append(list(connectA) + list(connectB))

  # do final permutation
  if len(connect_list[0]) > 0:
    if open_order is None:
      # default to conventional order
      tensor_out =  np.transpose(tensor_list[0], np.flip(np.argsort(connect_list[0])))
    else:
      # custom index order
      fin_perm = [connect_list[0].index(ele) for ele in open_order]
      tensor_out = np.transpose(tensor_list[0], fin_perm)
  else:
    # export 0-dim ndarray into scalar
    tensor_out = tensor_list[0].item()
  
  if return_info:
    return tensor_out, order, tot_cost
  else:
    return tensor_out


def partial_trace(labels, tensor=None, cont_inds=None):
  """ 
  Partial trace on `tensor` over matching `labels`. If no tensor is provided 
  then only the labels are updated to remove repeat entries. Returns the new
  tensor, its labels, the list of indices that were traced over, and the cost.
  """

  cost = 0
  if cont_inds is None:
    cont_inds = [ele for p, ele in enumerate(labels) if 
                 ele in labels[(p+1):]]
  num_cont = len(cont_inds)
  if num_cont > 0:
    cont_locs0 = [k for k, ele in enumerate(labels) if ((ele in cont_inds) and (ele not in labels[:k]))]
    cont_locs1 = [k for k, ele in enumerate(labels) if ((ele in cont_inds) and (ele not in labels[(k+1):]))]
    free_inds = [ele for ele in labels if ele not in cont_inds]
    free_locs = [k for k, ele in enumerate(labels) if ele not in cont_inds]

    # do partial trace as an index summation
    if tensor is not None:
      # dimensions of indices to trace
      shp = tensor.shape
      free_dim = [shp[k] for k in free_locs]
      cont_dim = np.prod([shp[k] for k in cont_locs0], dtype=np.uint64)

      cost = np.uint64(np.prod(free_dim)*cont_dim)
      B = np.zeros(np.prod(free_dim, dtype=np.uint64))
      tensor = tensor.transpose(free_locs + cont_locs0 + cont_locs1).reshape(
          np.prod(free_dim, dtype=np.uint64), cont_dim, cont_dim)
      for ip in range(cont_dim):
        B = B + tensor[:, ip, ip]

      return B.reshape(free_dim), free_inds, cost
    else:
      return free_inds, cost

  else:
    # no partial trace is needed
    return tensor, labels, cost

def do_node_contracts(tensors, connects, nodes, needed_conts, node_labs, 
                      nodes_occupied):
  """ 
  Contract all of the nodes needed to generate the full set of environments
  """
  
  N = nodes.shape[0] + 2
  while (sum(nodes_occupied) < len(nodes_occupied)):
    # poss_groups = node_labs[np.where(nodes_occupied)[0]]
    poss_groups = [lab for k, lab in enumerate(node_labs) if nodes_occupied[k]]
    temp_locs = [k for k, ele in enumerate(nodes.flatten()) if 
                 ele in poss_groups]
    
    # find the nodes contractions that we are able to do 
    poss_nodes = np.zeros(3 * (N-2), dtype=np.uint64)
    poss_nodes[temp_locs] = np.ones(len(temp_locs))
    poss_nodes = poss_nodes.reshape(N-2, 3)

    possible_types = np.zeros(((N-2), 3), dtype=bool)
    possible_types[:,0] = np.logical_and(poss_nodes[:,0], poss_nodes[:,1])
    possible_types[:,1] = np.logical_and(poss_nodes[:,0], poss_nodes[:,2])
    possible_types[:,2] = np.logical_and(poss_nodes[:,1], poss_nodes[:,2])

    # find first node that we need to do and are able to do
    nodes_to_do = np.logical_and(possible_types, needed_conts) # parallelize me!
    xpos, ypos = np.divmod(np.where(nodes_to_do.flatten())[0][0], 3)
    if ypos == 0:
      ctype = [0, 1, 2]
    elif ypos == 1:
      ctype = [0, 2, 1]
    elif ypos == 2:
      ctype = [1, 2, 0]

    # do node contractions
    node_cont = [nodes[xpos, ctype[0]], nodes[xpos, ctype[1]],
                 nodes[xpos, ctype[0]] + nodes[xpos, ctype[1]]]
    node_locs = [node_labs.index(node) for node in node_cont]
    
    conA = connects[node_locs[0]]
    conB = connects[node_locs[1]]
    cont_many, A_cont, B_cont, conC = intersect_lists(conA, conB)

    tensors[node_locs[2]] = np.tensordot(
        tensors[node_locs[0]], tensors[node_locs[1]],
        axes=(A_cont, B_cont))
    connects[node_locs[2]] = conC
    
    # update node information 
    needed_conts[xpos, ypos] = False
    nodes_occupied[node_locs[2]] = 1

    # identify intermediate tensors that are no longer needed
    temp_loc0 = -1
    temp_loc1 = -1
    if ypos == 0:
      if not needed_conts[xpos, 1]:
        temp_loc0 = np.where(node_labs == nodes[xpos,0])[0][0]
      if not needed_conts[xpos, 2]:
        temp_loc1 = np.where(node_labs == nodes[xpos,1])[0][0]
    elif ypos == 1:
      if not needed_conts[xpos, 0]:
        temp_loc0 = np.where(node_labs == nodes[xpos,0])[0][0]
      if not needed_conts[xpos, 2]:
        temp_loc1 = np.where(node_labs == nodes[xpos,2])[0][0]
    elif ypos == 2:
      if not needed_conts[xpos, 0]:
        temp_loc0 = np.where(node_labs == nodes[xpos,1])[0][0]
      if not needed_conts[xpos, 1]:
        temp_loc1 = np.where(node_labs == nodes[xpos,2])[0][0]
    
    # delete intermidate tensors to free memory
    if (temp_loc0 >= 0) and (temp_loc1 >= 0):
      del tensors[max(temp_loc0, temp_loc1)]
      del tensors[min(temp_loc0, temp_loc1)]
      del connects[max(temp_loc0, temp_loc1)]
      del connects[min(temp_loc0, temp_loc1)]
      nodes_occupied = np.delete(nodes_occupied, max(temp_loc0, temp_loc1))
      nodes_occupied = np.delete(nodes_occupied, min(temp_loc0, temp_loc1))
      del node_labs[max(temp_loc0, temp_loc1)]
      del node_labs[min(temp_loc0, temp_loc1)]
    elif temp_loc0 >= 0:
      del tensors[temp_loc0]
      del connects[temp_loc0]
      nodes_occupied = np.delete(nodes_occupied,temp_loc0)
      del node_labs[temp_loc0]
    elif temp_loc1 >= 0:
      del tensors[temp_loc1]
      del connects[temp_loc1]
      nodes_occupied = np.delete(nodes_occupied,temp_loc1)
      del node_labs[temp_loc1]
      
  return tensors, connects, node_labs


def remove_tensor(connects_in, which_env, order=None, open_order=None,
                  relabel_outputs=True, one_based=False):
  """
  Given a closed network and contraction order as input, will output a network 
  and new contraction order for the single tensor environment specified by the 
  input `which_env`. The new contraction order is gauranteed to be of lesser 
  or equivalent cost to that of the input order. Output network can either be
  standardized (+ve ints for internal indices and -ve ints for open indices) or
  retain the original labels. Open indices can either use zero-based numbering
  (default) or one-based numbering.
  """
  
  # generate contraction order if necessary
  connects = [connect for connect in connects_in]
  if order is None:
    flat_connect = [item for sublist in connects for item in sublist]
    order_new = [ele for k, ele in enumerate(flat_connect) if 
                 ele in flat_connect[(k+1):]]
  else:
    order_new = [ele for ele in list(order)]
  
  # find the new order of contraction
  nodes = find_nodes(connects, order_new)[0]
  order_out = node_to_order(connects, nodes, which_env)

  if relabel_outputs:
    # put connect labels into standardized form 
    fin_connects = [connect.copy() for connect in connects]
    temp_ord = fin_connects.pop(which_env)
    for p, connect in enumerate(fin_connects):
      for k, ele in enumerate(connect):
        if ele in temp_ord:
          fin_connects[p][k] = -temp_ord.index(ele)-one_based
          
    open_ord = list(range(-one_based, -len(fin_connects)-one_based, -1))
  else:
    # put connect labels back into original form 
    order_out = [order_out[k] for k in range(len(order_out))]
    fin_connects = [connect for connect in connects_in]
    open_ord = fin_connects.pop(which_env)
    
  return fin_connects, order_out, open_ord


def reorder_nodes(nodes, which_envs):
  """ 
  Find the set of node contractions required for all specified network 
  environments.
  """
  
  if isinstance(which_envs, int):
    which_envs = [which_envs]

  # Initializations
  N = nodes.shape[0] + 2
  node_labs = np.zeros((len(which_envs), 2 * (N - 2)), dtype=np.uint64)
  pos_vec = 3*np.arange(N-2, dtype=np.uint64)

  # transform nodes to string form (binary rep)
  form = '0' + str(N+1) + 'b' 
  bin_nodes = [format(ele, form) for ele in list(nodes.flatten())]

  # compute the collection of needed node contractions
  needed_conts = np.zeros(3 * (N - 2), dtype=bool)
  for count, env in enumerate(which_envs):
    temp_locs = np.where(np.logical_not(np.array([int(ele[N - env]) 
      for ele in bin_nodes], dtype=bool)))[0]
    node_labs[count,:] = nodes.flatten()[temp_locs]
    temp_type = np.sum(np.mod(temp_locs, 3).reshape(N - 2, 2), 
                      axis=1).astype(np.uint64) - 1
    needed_conts[temp_type + pos_vec] = np.ones(N - 2, dtype=bool)

  # add final envs to the list of nodes
  for env in which_envs:
    node_labs = np.append(node_labs, np.uint64(2**N - 1 - 2**env))
  node_labs = node_labs.flatten()
  node_labs = [lab for k, lab in enumerate(node_labs) if lab not in node_labs[(k+1):]]
  node_labs.sort()

  return node_labs, needed_conts.reshape(N-2,3)


def make_canon_connects(connects, order=None, open_order=None, one_based=False):
  """
  Takes in a set of `connects` defining a network, where index labels can be
  given either as `int` or `str` and returns dicts mapping between cannonical
  labels: where open (external) indices are labelled with negative integers 
  (starting at -'start') and closed (internal) indices are labelled with 
  positive integers (starting at +1). Sorting of indices of internal and open
  indices can either be provided (via 'order' and 'open_order') or will default
  to strings (alphabetical order) followed by integers (ascending order). Also 
  returns dictionaries for transforming between original and canonical indices.
  """

  # flatten the list of connections
  connects = [list(connect) for connect in connects]
  flat_connects = [item for sublist in connects for item in sublist]

  # separate ints from strs
  int_connects = []
  str_connects = []
  for ele in flat_connects:
    if isinstance(ele, str):
      str_connects.append(ele)
    else:
      int_connects.append(ele)
    
  # separate single (open) indices from double (closed) indices
  sgl_str = []
  dbl_str = []
  for ele in str_connects:
    if str_connects.count(ele) == 1:
      sgl_str.append(ele)
    elif str_connects.count(ele) == 2:
      if dbl_str.count(ele) == 0:
        dbl_str.append(ele)
    else:
      raise ValueError("index label {ind} is repeated more than twice".format(
          ind = "`" + ele + "`"))

  sgl_int = []
  dbl_int = []
  for ele in int_connects:
    if int_connects.count(ele) == 1:
      sgl_int.append(ele)
    elif int_connects.count(ele) == 2:
      if dbl_int.count(ele) == 0:
        dbl_int.append(ele)
    else:
      raise ValueError("index label {ind} is repeated more than twice".format(
          ind = "`" + str(ele) + "`"))
  
  # sort and combine index labels
  if order is None:
    # use standard order
    dbl_str.sort()
    dbl_int.sort()
    clsd_inds = dbl_str + dbl_int
  else:
    # user-defined order
    clsd_inds = order

  if open_order is None:
    # use standard order
    sgl_str.sort()
    sgl_int.sort()
    sgl_int.reverse()
    open_inds = sgl_str + sgl_int
  else:
    # user-defined order
    open_inds = open_order

  num_pos = len(clsd_inds)
  num_neg = len(open_inds)

  # create dictionary to map between original and cannonical labels
  neg_labs = dict(zip(open_inds, -np.arange(one_based,len(open_inds) + 
                                            one_based)))
  pos_labs = dict(zip(clsd_inds, np.arange(1,len(clsd_inds) + 1)))
  fwd_dict = {**neg_labs, **pos_labs}
  rev_dict = dict(zip(fwd_dict.values(), fwd_dict.keys()))

  # make canonical connections
  can_connects = []
  for tensor in connects:
    temp_inds = []
    for lab in list(tensor):
      temp_inds.append(fwd_dict[lab])
    can_connects.append(np.array(temp_inds, dtype=int))

  return can_connects, fwd_dict, rev_dict, num_pos, num_neg


def make_canon_dims(dims):
  """ 
  Create dict holding the unique tensor dims, which may be input either as 
  strings or integers, and transform the dims according to this dict. 
  """
  
  # flatten the list of connections
  flat_dims = [item for sublist in dims for item in sublist]

  # find unique entries
  uni_dims = []
  for ele in flat_dims:
    if ele not in uni_dims:
      uni_dims.append(ele)
  
  # create dictionary to map between original and cannonical dims
  fwd_dict = dict(zip(uni_dims, np.arange(len(uni_dims))))
  rev_dict = dict(zip(np.arange(len(uni_dims)), uni_dims))

  # make canonical dims
  can_dims = []
  for tensor in dims:
    temp_dims = []
    for lab in tensor:
      temp_dims.append(fwd_dict[lab])
    can_dims.append(np.array(temp_dims, dtype=int))

  return can_dims, fwd_dict, rev_dict


def compute_costs(connects, order=None, dims=None, return_pt=False):
  """ 
  Computes the cost of the sequence of binary contractions (and optionally also
  the partial traces) require to contract a network given some `order`. Input
  `dims` can be symbolic (strings) or numeric (ints), or a combination of both.
  """

  # define default dims everywhere as `d`
  if dims is None:
    dims = []
    for tensor in connects:
      dims.append(['d'] * len(tensor))

  # build dictionary between original and canonical dims
  nml_dims, fwd_dim_dict, rev_dim_dict = make_canon_dims(dims)
  
  # build dictionary between original and canonical dims
  nml_connects, fwd_dict, _, npos, num_neg = make_canon_connects(connects)
  keep_connects = [connect for connect in nml_connects]

  # find canonical order
  if order is None:
    nml_order = np.arange(npos) + 1
  else:
    nml_order = np.array([fwd_dict[ele] for ele in order])

  # indentify partial trace indices to be contracted
  pt_cont = []
  for count, sublist in enumerate(nml_connects):
    uni_labs, uni_locs = np.unique(sublist, return_index=True)
    num_cont = len(sublist) - len(uni_labs)
    if num_cont > 0:
      dup_list = []
      for ele in uni_labs:
        temp_locs = np.where(sublist == ele)[0]
        if len(temp_locs) == 2:
          dup_list.append(ele)
          sublist = np.delete(sublist, temp_locs)
          nml_order = np.delete(nml_order, nml_order==ele)
      
      pt_cont.append(np.array(dup_list))
      nml_connects[count] = sublist

  # indentify binary contraction indices 
  bn_cont = []
  while len(nml_order) > 0:
    locs = [ele for ele in range(len(nml_connects)) 
            if sum(nml_connects[ele] == nml_order[0]) > 0]

    cont_many, A_cont, B_cont = np.intersect1d(
        nml_connects[locs[0]],
        nml_connects[locs[1]],
        assume_unique=True,
        return_indices=True)
    
    bn_cont.append(cont_many)
    nml_connects.append(np.concatenate((
      np.delete(nml_connects[locs[0]], A_cont),
      np.delete(nml_connects[locs[1]], B_cont))))
    del nml_connects[locs[1]]
    del nml_connects[locs[0]]
    nml_order = np.delete(nml_order, np.intersect1d(nml_order, 
                                                    cont_many, 
                                                    return_indices=True)[1])

  # compute partial trace costs
  nml_connects = keep_connects
  pt_costs = []
  for pt_labs in pt_cont:
    for count, sublist in enumerate(nml_connects):
      pt_inds, pt_locs0, _ = np.intersect1d(
          sublist, pt_labs, return_indices=True)
      if len(pt_inds) > 0:
        sublist = np.delete(sublist, pt_locs0)
        cont_cost = np.delete(nml_dims[count], pt_locs0)
        _, pt_locs1, _ = np.intersect1d(sublist, pt_labs, return_indices=True)
        
        nml_connects[count] = np.delete(sublist, pt_locs1)
        nml_dims[count] = np.delete(cont_cost, pt_locs1)
        break
    pt_costs.append(cont_cost)
    
  # compute binary contraction costs
  bn_costs = []
  for bn_labs in bn_cont:
    locs = [ele for ele in range(len(nml_connects)) if 
            sum(nml_connects[ele] == bn_labs[0]) > 0]
    cont_many, A_cont, B_cont = np.intersect1d(
        nml_connects[locs[0]],
        nml_connects[locs[1]],
        assume_unique=True,
        return_indices=True)

    nml_connects.append(np.concatenate((
        np.delete(nml_connects[locs[0]], A_cont),
        np.delete(nml_connects[locs[1]], B_cont))))
    bn_costs.append(np.concatenate((
        np.delete(nml_dims[locs[0]], A_cont), nml_dims[locs[1]])))
    nml_dims.append(np.concatenate((
        np.delete(nml_dims[locs[0]], A_cont),
        np.delete(nml_dims[locs[1]], B_cont))))

    del nml_connects[locs[1]]
    del nml_connects[locs[0]]
    del nml_dims[locs[1]]
    del nml_dims[locs[0]]

  # tally the total partial trace costs
  int_pt_costs = []
  fin_pt_costs = []
  for cost in pt_costs:
    uni_dims = np.unique(cost)
    str_cost = ''
    int_cost = 1
    for dim in uni_dims:
      degen = sum(cost == dim)
      if rev_dim_dict is None:
        value = dim
      else:
        value = rev_dim_dict[dim]

      if isinstance(value, str):
        str_cost += '(' + str(value) + '^' + str(degen) + ')'
      else:
        int_cost = int_cost * value**degen
      
    int_pt_costs.append(int_cost)
    if int_cost > 1:
      if int_cost > 1000:
        if len(str_cost) > 0:
          fin_pt_costs.append("{:.1e}".format(int_cost) + '*' + str_cost)
        else:
          fin_pt_costs.append(int_cost)
      else:
        if len(str_cost) > 0:
          fin_pt_costs.append(str(int_cost) + '*' + str_cost)
        else:
          fin_pt_costs.append(int_cost)
    else:
      fin_pt_costs.append(str_cost)

  # tally the total binary contraction costs
  int_bn_costs = []
  fin_bn_costs = []
  for cost in bn_costs:
    uni_dims = np.unique(cost)
    str_cost = ''
    int_cost = 1
    for dim in uni_dims:
      degen = sum(cost == dim)
      if rev_dim_dict is None:
        value = dim
      else:
        value = rev_dim_dict[dim]

      if isinstance(value, str):
        str_cost += '(' + str(value) + '^' + str(degen) + ')'
      else:
        int_cost = int_cost * value**degen

    int_bn_costs.append(int_cost)
    if int_cost > 1:
      if int_cost > 1000:
        if len(str_cost) > 0:
          fin_bn_costs.append("{:.1e}".format(int_cost) + '*' + str_cost)
        else:
          fin_bn_costs.append(int_cost)
      else:
        if len(str_cost) > 0:
          fin_bn_costs.append(str(int_cost) + '*' + str_cost)
        else:
          fin_bn_costs.append(int_cost)
    else:
      fin_bn_costs.append(str_cost)

  if return_pt:
    return fin_bn_costs, fin_pt_costs
  else:
    return fin_bn_costs


def check_network(connects, dims, order, rev_dict=None, rev_dim_dict=None):
  """ 
  Check the validity of a network. Require input `connects` to already be in
  canonical form (+ve ints for internal inds and -ve ints for external).
  """

  flat_connect = [item for sublist in connects for item in sublist]   
  pos_ind = [ele for k, ele in enumerate(flat_connect) if 
             ele in flat_connect[(k+1):]]
  
  unilabs, counts = np.unique(flat_connect, return_counts=True)
  if any(counts > 2):
    lab = unilabs[np.where(counts > 2)[0][0]]
    raise ValueError(
    'Network definition error: more than two indices labelled {n0}'
        .format(n0 = "`" + str(lab) + "`"))

  # check that lengths of lists match
  if len(dims) != len(connects):
    raise ValueError((
        'Network definition error: mismatch between {n0} tensors given but {n1}'
        ' index sublists given'.format(n0 = str(len(dims)), 
                                       n1 = str(len(connects)))))

  # check that tensors have the right number of indices
  for ele in range(len(dims)):
    if len(dims[ele]) != len(connects[ele]):
      raise ValueError(
          'Network definition error: number of indices does not match number'
          ' of labels on tensor {n0}: {n1}-indices versus {n2}-labels'.format(
              n0 = str(ele),
              n1 = str(len(dims[ele])),
              n2 = str(len(connects[ele]))))

  # check that contraction order is valid
  for ele in pos_ind:
    if ele not in order:
      raise ValueError('Network definition error: invalid contraction order')

  # contracted tensor dimensions match
  flat_dims = [item for sublist in dims for item in sublist]
  for ind in pos_ind:
    p0 = flat_connect.index(ind)
    flat_connect.pop(p0)
    p1 = flat_connect.index(ind)
    flat_connect.pop(p1)
    d0 = flat_dims.pop(p0) 
    d1 = flat_dims.pop(p1)
    if d0 != d1:
      if rev_dim_dict is not None:
        d0 = rev_dim_dict[d0]
        d1 = rev_dim_dict[d1]

      if rev_dict is not None:
        ind_temp = rev_dict[ind]
      else:
        ind_temp = ind

      raise ValueError(
          'Network definition error: tensor dimension mismatch on'
          ' index labelled {n0}: dim-{n1} versus dim-{n2}'
          .format(n0 = "`" + str(ind_temp) + "`", 
                  n1 = str(d0), 
                  n2 = str(d1)))

  return True